{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac1b705-354d-4e6a-bb30-b57d053e442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8afb99-5c36-4460-838b-47e4e409508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import econml\n",
    "\n",
    "from rashomon import tva\n",
    "from rashomon import loss\n",
    "from rashomon import counter\n",
    "from rashomon import metrics\n",
    "from rashomon import extract_pools\n",
    "from rashomon.aggregate import (RAggregate_profile, RAggregate,\n",
    "    find_profile_lower_bound, find_feasible_combinations, remove_unused_poolings, subset_data)\n",
    "from rashomon.sets import RashomonSet, RashomonProblemCache, RashomonSubproblemCache\n",
    "from rashomon.aggregate import find_te_het_partitions\n",
    "\n",
    "from econml.grf import CausalForest\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176ab43-dc32-46fb-958e-ce465bafc0f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1023160-4425-49dd-a032-3c83624167de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting econml\n",
      "  Downloading econml-0.15.0.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from econml) (1.24.3)\n",
      "Requirement already satisfied: scipy>1.4.0 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from econml) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn<1.5,>=1.0 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from econml) (1.3.0)\n",
      "Collecting sparse (from econml)\n",
      "  Obtaining dependency information for sparse from https://files.pythonhosted.org/packages/07/a3/22e031f6833d84edd54b0809087d910907358bddc1c92e56b7b2db30f5ed/sparse-0.15.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading sparse-0.15.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: joblib>=0.13.0 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from econml) (1.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.10 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from econml) (0.14.0)\n",
      "Requirement already satisfied: pandas>1.0 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from econml) (2.0.3)\n",
      "Collecting shap<0.44.0,>=0.38.1 (from econml)\n",
      "  Obtaining dependency information for shap<0.44.0,>=0.38.1 from https://files.pythonhosted.org/packages/fb/99/2364cc073662517335383f68a10549c6b75486b99f0d671179e4dd8252d6/shap-0.43.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading shap-0.43.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Collecting lightgbm (from econml)\n",
      "  Downloading lightgbm-4.3.0.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from pandas>1.0->econml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from pandas>1.0->econml) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from pandas>1.0->econml) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from scikit-learn<1.5,>=1.0->econml) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (23.1)\n",
      "Collecting slicer==0.0.7 (from shap<0.44.0,>=0.38.1->econml)\n",
      "  Obtaining dependency information for slicer==0.0.7 from https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl.metadata\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numba in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (0.57.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (2.2.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.10->econml) (0.5.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from numba->shap<0.44.0,>=0.38.1->econml) (0.40.0)\n",
      "Requirement already satisfied: six in /Users/brianxu/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels>=0.10->econml) (1.16.0)\n",
      "Downloading shap-0.43.0-cp311-cp311-macosx_11_0_arm64.whl (445 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.4/445.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Downloading sparse-0.15.1-py2.py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: econml, lightgbm\n",
      "  Building wheel for econml (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for econml: filename=econml-0.15.0-cp311-cp311-macosx_11_0_arm64.whl size=1956746 sha256=76a41ab5f7860030d47e85eac9600b22164750cdd6db726cb206b7e35e64840a\n",
      "  Stored in directory: /Users/brianxu/Library/Caches/pip/wheels/1f/42/a4/8b98b066036f946d759d953d13c1e6adbce33e94d5e11ec512\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for lightgbm \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[42 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:32,920 - scikit_build_core - INFO - RUN: /private/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/pip-build-env-5dcw9drw/normal/lib/python3.11/site-packages/cmake/data/bin/cmake -E capabilities\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:32,926 - scikit_build_core - INFO - CMake version: 3.29.2\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1m\u001b[92mscikit-build-core 0.9.2\u001b[0m using \u001b[94mCMake 3.29.2\u001b[0m \u001b[91m(wheel)\u001b[0m\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:32,929 - scikit_build_core - INFO - Build directory: /private/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/tmpdac1jwz5/build\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mConfiguring CMake...\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:32,939 - scikit_build_core - INFO - RUN: /private/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/pip-build-env-5dcw9drw/normal/lib/python3.11/site-packages/ninja/data/bin/ninja --version\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:33,019 - scikit_build_core - INFO - Ninja version: 1.11.1\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:33,020 - scikit_build_core - WARNING - libdir/ldlibrary: /Users/brianxu/anaconda3/lib/libpython3.11.a is not a real file!\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:33,020 - scikit_build_core - WARNING - Can't find a Python library, got libdir=/Users/brianxu/anaconda3/lib, ldlibrary=libpython3.11.a, multiarch=darwin, masd=None\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:33,021 - scikit_build_core - INFO - RUN: /private/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/pip-build-env-5dcw9drw/normal/lib/python3.11/site-packages/cmake/data/bin/cmake -S. -B/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/tmpdac1jwz5/build -DCMAKE_BUILD_TYPE:STRING=Release -C/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/tmpdac1jwz5/build/CMakeInit.txt -DCMAKE_MAKE_PROGRAM=/private/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/pip-build-env-5dcw9drw/normal/lib/python3.11/site-packages/ninja/data/bin/ninja -D__BUILD_FOR_PYTHON:BOOL=ON\n",
      "  \u001b[31m   \u001b[0m loading initial cache file /var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/tmpdac1jwz5/build/CMakeInit.txt\n",
      "  \u001b[31m   \u001b[0m -- The C compiler identification is AppleClang 15.0.0.15000040\n",
      "  \u001b[31m   \u001b[0m -- The CXX compiler identification is AppleClang 15.0.0.15000040\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES)\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND)\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP_C: -Xpreprocessor -fopenmp -I/opt/homebrew/opt/libomp/include\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP_CXX: -Xpreprocessor -fopenmp -I/opt/homebrew/opt/libomp/include\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP: TRUE\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH - Failed\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC - Success\n",
      "  \u001b[31m   \u001b[0m -- Using _mm_malloc\n",
      "  \u001b[31m   \u001b[0m -- Configuring done (0.9s)\n",
      "  \u001b[31m   \u001b[0m -- Generating done (0.0s)\n",
      "  \u001b[31m   \u001b[0m -- Build files have been written to: /var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/tmpdac1jwz5/build\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mBuilding project with \u001b[94mNinja\u001b[0m...\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-04-25 16:09:33,964 - scikit_build_core - INFO - RUN: /private/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/pip-build-env-5dcw9drw/normal/lib/python3.11/site-packages/cmake/data/bin/cmake --build /var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/tmpdac1jwz5/build\n",
      "  \u001b[31m   \u001b[0m ninja: error: '/opt/homebrew/opt/libomp/lib/libomp.dylib', needed by '/private/var/folders/m3/pz21nfxs75xgf_18thskgtw40000gn/T/pip-install-xvzfdv7w/lightgbm_3aeb7b5a409641388d889586582e5749/lib_lightgbm.so', missing and no known rule to make it\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[91m\u001b[1m*** CMake build failed\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for lightgbm\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully built econml\n",
      "Failed to build lightgbm\n",
      "\u001b[31mERROR: Could not build wheels for lightgbm, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fb161c-7264-4757-a431-03ca8d65538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(mu, var, n_per_pol, all_policies, pi_policies, M):\n",
    "    num_data = num_policies * n_per_pol\n",
    "    X = np.zeros(shape=(num_data, M))\n",
    "    D = np.zeros(shape=(num_data, 1), dtype='int_')\n",
    "    y = np.zeros(shape=(num_data, 1))  + np.inf\n",
    "    mu_true = np.zeros(shape=(num_data, 1))\n",
    "\n",
    "    idx_ctr = 0\n",
    "    for k, profile in enumerate(profiles):\n",
    "        policies_k = policies_profiles[k]\n",
    "\n",
    "        for idx, policy in enumerate(policies_k):\n",
    "            policy_idx = [i for i, x in enumerate(all_policies) if x == policy]\n",
    "            \n",
    "            if pi_policies[k] is None and np.isnan(mu[k]):\n",
    "                continue\n",
    "                \n",
    "            pool_id = pi_policies[k][idx]\n",
    "            mu_i = mu[k][pool_id]\n",
    "            var_i = var[k][pool_id]\n",
    "            y_i = np.random.normal(mu_i, var_i, size=(n_per_pol, 1))\n",
    "\n",
    "            start_idx = idx_ctr * n_per_pol\n",
    "            end_idx = (idx_ctr + 1) * n_per_pol\n",
    "\n",
    "            X[start_idx:end_idx, ] = policy\n",
    "            D[start_idx:end_idx, ] = policy_idx[0]\n",
    "            y[start_idx:end_idx, ] = y_i\n",
    "            mu_true[start_idx:end_idx, ] = mu_i\n",
    "\n",
    "            idx_ctr += 1\n",
    "\n",
    "    absent_idx = np.where(np.isinf(y))[0]\n",
    "    X = np.delete(X, absent_idx, 0)\n",
    "    y = np.delete(y, absent_idx, 0)\n",
    "    D = np.delete(D, absent_idx, 0)\n",
    "    mu_true = np.delete(mu_true, absent_idx, 0)\n",
    "\n",
    "    return X, D, y, mu_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a5645-0e7c-433d-bd17-912ffa483778",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7506afbd-bf05-4f34-9f35-c6d3bdfe11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = 4\n",
    "# R = np.array([2, 5, 5, 5])\n",
    "\n",
    "\n",
    "# # (0, 1, 1, 1)\n",
    "# sigma_0 = np.array([[1, 1, 1],\n",
    "#                     [1, 1, 1],\n",
    "#                     [1, 1, 1]\n",
    "#                    ])\n",
    "# mu_0 = np.array([0])\n",
    "# var_0 = np.array([0])\n",
    "\n",
    "# # (1, 1, 1)\n",
    "# sigma_1 = np.array([[np.inf, np.inf, np.inf],\n",
    "#                     [1, 1, 1],\n",
    "#                     [1, 0, 1],\n",
    "#                     [1, 0, 0],\n",
    "#                    ])\n",
    "# mu_1 = np.array([2, 4, 7, 5, 6, 3])\n",
    "# var_1 = np.array([1, 1, 1, 1, 1, 1]) * 0.5\n",
    "\n",
    "\n",
    "# interested_profiles = [(0, 1, 1, 1), (1, 1, 1, 1)]\n",
    "\n",
    "# sigma_tmp = [sigma_0, sigma_1]\n",
    "# mu_tmp = [mu_0, mu_1]\n",
    "# var_tmp = [var_0, var_1]\n",
    "\n",
    "M = 3\n",
    "R = np.array([2, 4, 5, 5])\n",
    "\n",
    "\n",
    "# (0, 1, 1, 1)\n",
    "sigma_0 = np.array([[1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1]\n",
    "                   ])\n",
    "mu_0 = np.array([0])\n",
    "var_0 = np.array([1])\n",
    "\n",
    "# (1, 1, 1)\n",
    "sigma_1 = np.array([[np.inf, np.inf, np.inf],\n",
    "                    [0, 0, np.inf],\n",
    "                    [1, 0, 1],\n",
    "                    [1, 1, 0],\n",
    "                   ])\n",
    "mu_1 = np.array([2, 4, 2, 0, 3, 5, 7, 1, 1, -1, -1, -2])\n",
    "var_1 = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "\n",
    "interested_profiles = [(0, 1, 1, 1), (1, 1, 1, 1)]\n",
    "\n",
    "sigma_tmp = [sigma_0, sigma_1]\n",
    "mu_tmp = [mu_0, mu_1]\n",
    "var_tmp = [var_0, var_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd707c6-f3b0-4840-ace8-0c05bba86f8a",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    \\text{Control} & \\\\\n",
    "    (0,\\ 1:3,\\  1:4,\\  1:4) &= 0 \\\\\n",
    "    \\text{Treatment} & \\\\\n",
    "    (1,\\  1,\\  1:2,\\  1:3) &= 2 \\\\\n",
    "    (1,\\  1,\\  1:2,\\  4) &= 4 \\\\\n",
    "    (1,\\  1,\\  3:4,\\  1:3) &= 2 \\\\\n",
    "    (1,\\  1,\\  3:4,\\  4) &= 0 \\\\\n",
    "    (1,\\  2,\\  1:2,\\  1:3) &= 3 \\\\\n",
    "    (1,\\  2,\\  1:2,\\  4) &= 5 \\\\\n",
    "    (1,\\  2,\\  3:4,\\  1:3) &= 7 \\\\\n",
    "    (1,\\  2,\\  3:4,\\  4) &= 1 \\\\\n",
    "    (1,\\  3,\\  1:2,\\  1:3) &= 1 \\\\\n",
    "    (1,\\  3,\\  1:2,\\  4) &= -1 \\\\\n",
    "    (1,\\  3,\\  3:4,\\  1:3) &= -1 \\\\\n",
    "    (1,\\  3,\\  3:4,\\  4) &= -2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f419b2-b595-462e-a53a-8c5caba75fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_profiles = 2**M\n",
    "profiles, profile_map = tva.enumerate_profiles(M)\n",
    "all_policies = tva.enumerate_policies(M, R)\n",
    "num_policies = len(all_policies)\n",
    "\n",
    "interested_profile_idx = []\n",
    "sigma = []\n",
    "mu = []\n",
    "var = []\n",
    "for k, profile in enumerate(profiles):\n",
    "    sigma_k = None\n",
    "    mu_k = np.nan\n",
    "    var_k =  np.nan\n",
    "    for i, p in enumerate(interested_profiles):\n",
    "        if p == profile:\n",
    "            sigma_k = sigma_tmp[i]\n",
    "            mu_k = mu_tmp[i]\n",
    "            var_k = var_tmp[i]\n",
    "            break\n",
    "    sigma.append(sigma_k)\n",
    "    mu.append(mu_k)\n",
    "    var.append(var_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bec8cf2-2221-4879-810b-acfe4a4396a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the pools\n",
    "policies_profiles = {}\n",
    "policies_profiles_masked = {}\n",
    "policies_ids_profiles = {}\n",
    "pi_policies = {}\n",
    "pi_pools = {}\n",
    "for k, profile in enumerate(profiles):\n",
    "\n",
    "    policies_temp = [(i, x) for i, x in enumerate(all_policies) if tva.policy_to_profile(x) == profile]\n",
    "    unzipped_temp = list(zip(*policies_temp))\n",
    "    policies_ids_k = list(unzipped_temp[0])\n",
    "    policies_k = list(unzipped_temp[1])\n",
    "    policies_profiles[k] = deepcopy(policies_k)\n",
    "    policies_ids_profiles[k] = policies_ids_k\n",
    "\n",
    "    profile_mask = list(map(bool, profile))\n",
    "\n",
    "    # Mask the empty arms\n",
    "    for idx, pol in enumerate(policies_k):\n",
    "        policies_k[idx] = tuple([pol[i] for i in range(M) if profile_mask[i]])\n",
    "    policies_profiles_masked[k] = policies_k\n",
    "\n",
    "\n",
    "    # profile_idx = None\n",
    "    # for idx, p in enumerate(interested_profiles):\n",
    "    #     if p == profile:\n",
    "    #         profile_idx = idx\n",
    "    # if profile_idx is None:\n",
    "    #     pi_policies[k] = None\n",
    "    #     pi_pools[k] = None\n",
    "    #     continue\n",
    "    if sigma[k] is None:\n",
    "        pi_policies[k] = None\n",
    "        pi_pools[k] = None\n",
    "        continue\n",
    "\n",
    "    if np.sum(profile) > 0:\n",
    "        pi_pools_k, pi_policies_k = extract_pools.extract_pools(policies_k, sigma[k])\n",
    "        if len(pi_pools_k.keys()) != mu[k].shape[0]:\n",
    "            print(pi_pools_k)\n",
    "            print(f\"Profile {k}. Expected {len(pi_pools_k.keys())} pools. Received {mu[k].shape[0]} means.\")\n",
    "        pi_policies[k] = pi_policies_k\n",
    "        # pi_pools_k has indicies that match with policies_profiles[k]\n",
    "        # Need to map those indices back to all_policies\n",
    "        pi_pools[k] = {}\n",
    "        for x, y in pi_pools_k.items():\n",
    "            y_full = [policies_profiles[k][i] for i in y]\n",
    "            y_agg = [all_policies.index(i) for i in y_full]\n",
    "            pi_pools[k][x] = y_agg\n",
    "    else:\n",
    "        pi_policies[k] = {0: 0}\n",
    "        pi_pools[k] = {0: [0]}\n",
    "\n",
    "best_per_profile = [np.max(mu_k) for mu_k in mu]\n",
    "true_best_profile = np.nanargmax(best_per_profile)\n",
    "true_best_profile_idx = int(true_best_profile)\n",
    "true_best_effect = np.max(mu[true_best_profile])\n",
    "true_best = pi_pools[true_best_profile][np.argmax(mu[true_best_profile])]\n",
    "min_dosage_best_policy = metrics.find_min_dosage(true_best, all_policies)\n",
    "\n",
    "# The transformation matrix for Lasso\n",
    "G = tva.alpha_matrix(all_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b66a56-3c11-48ab-9c14-2acbcd833b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_arm_idx = 0\n",
    "\n",
    "ctl_profile_idx = 7\n",
    "trt_profile_idx = 15\n",
    "\n",
    "ctl_profile = (0, 1, 1, 1)\n",
    "trt_profile = (1, 1, 1, 1)\n",
    "\n",
    "# Subset data for interested profiles\n",
    "trt_policies_ids = policies_ids_profiles[trt_profile_idx]\n",
    "ctl_policies_ids = policies_ids_profiles[ctl_profile_idx]\n",
    "tc_policies_ids = trt_policies_ids + ctl_policies_ids\n",
    "\n",
    "trt_policies = policies_profiles_masked[trt_profile_idx]\n",
    "ctl_policies = policies_profiles_masked[ctl_profile_idx]\n",
    "\n",
    "trt_pools, trt_pools_policies = extract_pools.extract_pools(trt_policies, sigma[trt_profile_idx])\n",
    "ctl_pools, ctl_pools_policies = extract_pools.extract_pools(ctl_policies, sigma[ctl_profile_idx])\n",
    "\n",
    "D_trt = np.array(list(trt_pools_policies.keys()))\n",
    "D_ctl = np.array(list(ctl_pools_policies.keys()))\n",
    "\n",
    "D_trt_pooled = [trt_pools_policies[pol_id] for pol_id in D_trt]\n",
    "D_ctl_pooled = [ctl_pools_policies[pol_id] for pol_id in D_ctl]\n",
    "y_trt = mu[trt_profile_idx][D_trt_pooled]\n",
    "y_ctl = mu[ctl_profile_idx][D_ctl_pooled]\n",
    "\n",
    "X_trt = np.array(policies_profiles[trt_profile_idx])[:, 1:]\n",
    "\n",
    "te_true = y_trt - y_ctl\n",
    "max_te = np.max(te_true)\n",
    "max_te_policies_p = D_trt[np.where(te_true == max_te)]\n",
    "max_te_policies = [policies_ids_profiles[trt_profile_idx][x] for x in max_te_policies_p]\n",
    "min_dosage_best_te = metrics.find_min_dosage(max_te_policies, all_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67efabc-5d96-42e3-a2c0-ceae957d45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pi, l in pi_pools[15].items():\n",
    "#     print(pi)\n",
    "#     print([all_policies[x] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867d5c2-5463-40b4-9557-d3327401901d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e201a3c-6a6a-458f-b9af-e4edb345f706",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba758a9-2544-4b07-b853-fec8c9795681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2a124-debe-411f-8e7f-dcf9f6bd914d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d6042b2-2d1a-4d08-ab6f-527bcc9f290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "n_per_pol = 10\n",
    "\n",
    "# Generate data\n",
    "X, D, y, mu_true = generate_data(mu, var, n_per_pol, all_policies, pi_policies, M)\n",
    "policy_means = loss.compute_policy_means(D, y, num_policies)\n",
    "# The dummy matrix for Lasso\n",
    "D_matrix = tva.get_dummy_matrix(D, G, num_policies)\n",
    "\n",
    "trt_arm_idx = 0\n",
    "feature_idx = list(np.arange(0, trt_arm_idx)) + list(np.arange(trt_arm_idx+1, M))\n",
    "\n",
    "T = np.zeros(shape=y.shape)\n",
    "T[X[:, trt_arm_idx] > 0] = 1\n",
    "\n",
    "y_0d = y.reshape((-1,))\n",
    "X_cf = X[:, feature_idx]\n",
    "\n",
    "X_trt_subset = X[X[:, trt_arm_idx] > 0, :]\n",
    "X_trt_subset = X_trt_subset[:, feature_idx]\n",
    "y_trt_subset = y[X[:, trt_arm_idx] > 0]\n",
    "\n",
    "\n",
    "D_trt_subset = D[X[:, trt_arm_idx] > 0]\n",
    "D_matrix_trt_subset = D_matrix[X[:, trt_arm_idx] > 0, :]\n",
    "D_matrix_ctl_subset = D_matrix[X[:, trt_arm_idx] == 0, :]\n",
    "\n",
    "D_trt_univ = np.array([policies_ids_profiles[trt_profile_idx][x] for x in D_trt]).reshape((-1, 1))\n",
    "D_ctl_univ = np.array([policies_ids_profiles[ctl_profile_idx][x] for x in D_ctl]).reshape((-1, 1))\n",
    "D_matrix_trt = tva.get_dummy_matrix(D_trt_univ, G, num_policies)\n",
    "D_matrix_ctl = tva.get_dummy_matrix(D_ctl_univ, G, num_policies)\n",
    "\n",
    "\n",
    "policy_means = loss.compute_policy_means(D, y, num_policies)\n",
    "\n",
    "mask = np.isin(D, tc_policies_ids)\n",
    "D_tc = D[mask].reshape((-1,1))\n",
    "y_tc = y[mask].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b039bfc-47ef-44cf-a48a-730bcdd2aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# policy_means_tc = policy_means[tc_policies_ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f17aa3-5cfa-4bec-8091-167c8960dbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56941d-1c9f-47dd-a846-30e056689adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48af61e0-8b18-40a2-8e3b-2ef0e91a392d",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "\n",
    "## Causal Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c5359e0-28a4-4dc6-9d78-2927add5f198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CausalForest(criterion=&#x27;het&#x27;, min_samples_leaf=10, random_state=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CausalForest</label><div class=\"sk-toggleable__content\"><pre>CausalForest(criterion=&#x27;het&#x27;, min_samples_leaf=10, random_state=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CausalForest(criterion='het', min_samples_leaf=10, random_state=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://econml.azurewebsites.net/_autosummary/econml.grf.CausalForest.html?highlight=causalforest#econml.grf.CausalForest\n",
    "est = CausalForest(criterion=\"het\", n_estimators=100,\n",
    "                   min_samples_leaf=10,\n",
    "                   # max_depth=None,\n",
    "                   min_samples_split=10,\n",
    "                   random_state=3,\n",
    "                  )\n",
    "\n",
    "# est.fit(X_cf, X[:, trt_idx], y_0d)\n",
    "est.fit(X_cf, T, y_0d)\n",
    "# est.fit(X, 1 + np.zeros(T.shape), y_0d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f99b5fff-f7b3-4350-81dd-0a165aa5d4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse_te': 1.484211437485257,\n",
       " 'max_te_est': 6.530341442900793,\n",
       " 'max_te_err': 0.4696585570992067,\n",
       " 'iou': 0.14285714285714285,\n",
       " 'conf_matrix': array([[0.8, 0. , 0.2],\n",
       "        [0. , 0. , 1. ],\n",
       "        [0. , 0. , 1. ]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_cf = est.predict(X_trt)\n",
    "\n",
    "cf_res = metrics.compute_te_het_metrics(\n",
    "                            te_true, te_cf,\n",
    "                            max_te, max_te_policies,\n",
    "                            D_trt, policies_ids_profiles[trt_profile_idx]\n",
    "                        )\n",
    "\n",
    "cf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5a53b-0504-4c2e-8e86-713e625679b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c66e6-c28f-4613-aa25-c7c490f77f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602dcb89-dbe6-4588-b514-243211892fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "159eabcc-5998-410b-babf-2cae24cae66a",
   "metadata": {},
   "source": [
    "## Rashomon Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0f44aea-24f0-4c77-b859-8ed93bff474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping profile (0, 0, 0, 0)\n",
      "Skipping profile (0, 0, 0, 1)\n",
      "Skipping profile (0, 0, 1, 0)\n",
      "Skipping profile (0, 0, 1, 1)\n",
      "Skipping profile (0, 1, 0, 0)\n",
      "Skipping profile (0, 1, 0, 1)\n",
      "Skipping profile (0, 1, 1, 0)\n",
      "(0, 1, 1, 1) 0.6902404523030581\n",
      "220\n",
      "Skipping profile (1, 0, 0, 0)\n",
      "Skipping profile (1, 0, 0, 1)\n",
      "Skipping profile (1, 0, 1, 0)\n",
      "Skipping profile (1, 0, 1, 1)\n",
      "Skipping profile (1, 1, 0, 0)\n",
      "Skipping profile (1, 1, 0, 1)\n",
      "Skipping profile (1, 1, 1, 0)\n",
      "(1, 1, 1, 1) 0.6848560440763305\n",
      "5\n",
      "Finding feasible combinations\n",
      "Min = 1.13590072054853, Max = 1.3516820539585388\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "H = np.inf\n",
    "\n",
    "\n",
    "theta = 1.15\n",
    "reg = 1e-2\n",
    "R_set, rashomon_profiles = RAggregate(M, R, H, D, y, theta, reg,\n",
    "                                     verbose=True,\n",
    "                                     )\n",
    "# theta = 3\n",
    "# reg = 1e-1\n",
    "# R_set, rashomon_profiles = RAggregate(M, R, H, D_trt_subset, y_trt_subset, theta, reg,\n",
    "#                                      verbose=True,\n",
    "#                                      )\n",
    "\n",
    "print(len(R_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed5a5d-7d92-4060-b84c-00f7d66a5c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4daa0e7-1add-48fd-b8b8-4ac3d2ec3cdd",
   "metadata": {},
   "source": [
    "### Find poolings across Treatment and Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3baef18a-45ee-43b1-8d83-c733fa92b72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b5ffa2b-d805-427c-a27d-2e760a0745f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "298950ca-746f-4024-b2fd-272cc3d3252d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "868d12ef-82e5-4537-b643-9242dd05da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrices = []\n",
    "results_list = []\n",
    "sim_i = 0\n",
    "\n",
    "for idx, r_set in enumerate(R_set):\n",
    "    conf_matrix_list_idx = []\n",
    "\n",
    "    sigma_trt_R_set_idx = r_set[trt_profile_idx]\n",
    "    sigma_trt_i = rashomon_profiles[trt_profile_idx].sigma[sigma_trt_R_set_idx]\n",
    "    sigma_ctl_R_set_idx = r_set[ctl_profile_idx]\n",
    "    sigma_ctl_i = rashomon_profiles[ctl_profile_idx].sigma[sigma_ctl_R_set_idx]\n",
    "\n",
    "    trt_pools_0, _ = extract_pools.extract_pools(trt_policies, sigma_trt_i)\n",
    "    ctl_pools_0, _ = extract_pools.extract_pools(ctl_policies, sigma_ctl_i) # This gives dictionary of pools --> this is the partition\n",
    "\n",
    "    # Right now the treatment and control profiles are not pooled together; need to check if it is possible to pool together treatment and control\n",
    "\n",
    "    for (ti, ci) in zip(trt_policies, ctl_policies):\n",
    "        ti = tuple(ti[:trt_arm_idx] + ti[(trt_arm_idx+1):])\n",
    "        if ti != ci:\n",
    "            raise RuntimeError(\"Treatment and control pairs do not match!\")\n",
    "\n",
    "    trt_pools = tva.profile_ids_to_univ_ids(trt_pools_0, trt_policies_ids)\n",
    "    ctl_pools = tva.profile_ids_to_univ_ids(ctl_pools_0, ctl_policies_ids)\n",
    "\n",
    "    P_qe_idx = te_partitions[idx]\n",
    "\n",
    "    for te_pool_id, sigma_int in enumerate(P_qe_idx.sigma):\n",
    "        sigma_pools, sigma_policies = extract_pools.get_trt_ctl_pooled_partition(\n",
    "            trt_pools, ctl_pools, sigma_int\n",
    "        )\n",
    "        mu_pools = loss.compute_pool_means(policy_means, sigma_pools)\n",
    "        D_tc_pool = [sigma_policies[pol_id] for pol_id in D_tc[:, 0]]\n",
    "        mu_D = mu_pools[D_tc_pool]\n",
    "\n",
    "        # Find TE\n",
    "        D_trt_pooled_i = [sigma_policies[pol_id] for pol_id in trt_policies_ids]\n",
    "        D_ctl_pooled_i = [sigma_policies[pol_id] for pol_id in ctl_policies_ids]\n",
    "        y_trt_i = mu_pools[D_trt_pooled_i]\n",
    "        y_ctl_i = mu_pools[D_ctl_pooled_i]\n",
    "\n",
    "        te_i = y_trt_i - y_ctl_i\n",
    "\n",
    "        metrics_results_i = metrics.compute_te_het_metrics(\n",
    "            te_true, te_i,\n",
    "            max_te, max_te_policies,\n",
    "            D_trt, policies_ids_profiles[trt_profile_idx]\n",
    "        )\n",
    "        mse_te_i = metrics_results_i[\"mse_te\"]\n",
    "        max_te_err_i = metrics_results_i[\"max_te_err\"]\n",
    "        iou_i = metrics_results_i[\"iou\"]\n",
    "        conf_mat_i = metrics_results_i[\"conf_matrix\"]\n",
    "\n",
    "        # Compute overall MSE\n",
    "        mse_i = mean_squared_error(y_tc[:, 0], mu_D)\n",
    "\n",
    "        # Count number of pools\n",
    "        num_pools_i = len(sigma_pools.keys())\n",
    "\n",
    "        results_i = [\n",
    "            n_per_pol, sim_i, idx, te_pool_id,\n",
    "            mse_te_i, max_te_err_i, iou_i,\n",
    "            mse_i, num_pools_i\n",
    "        ]\n",
    "        results_list.append(results_i)\n",
    "\n",
    "        conf_matrix_list_idx.append(conf_mat_i)\n",
    "        \n",
    "    conf_matrices.append(conf_matrix_list_idx)\n",
    "\n",
    "rashomon_cols = [\n",
    "            \"n_per_pol\", \"sim_num\", \"idx\", \"te_idx\",\n",
    "            \"MSE_TE\", \"max_te_diff\", \"IOU\", \"MSE\", \"num_pools\"\n",
    "        ]\n",
    "rashomon_df = pd.DataFrame(results_list, columns=rashomon_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3c3ce09-5bd0-4669-abe4-dad362328703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.202740279341172"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rashomon_df[\"MSE_TE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8510d37f-c4c7-4bc1-a022-aa21e8e4236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_models = 0\n",
    "for P_i in te_partitions:\n",
    "    num_models += P_i.size\n",
    "print(num_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11afd674-c217-42b4-a3c6-f640996c8fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712711b-de0a-4af5-a0e1-454b6938da85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20b86b-d1f4-4140-9074-7c7d95ace6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091dae4-b30e-448d-b718-f8675a7d43d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aea13a-c7cd-4359-867b-95777c7301e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c714815f-62da-42f9-8ed5-26e7225e160f",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab416e32-535d-40ac-bdf0-45521ce21ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = 1e-1\n",
    "\n",
    "\n",
    "lasso = linear_model.Lasso(lasso_reg, fit_intercept=False)\n",
    "lasso.fit(D_matrix, y)\n",
    "# lasso.fit(X_trt_subset, y_trt_subset)\n",
    "alpha_est = lasso.coef_\n",
    "\n",
    "\n",
    "# y_tva = lasso.predict(D_matrix_trt_subset)\n",
    "# # y_tva = lasso.predict(X_trt_subset)\n",
    "\n",
    "# tva_results = metrics.compute_all_metrics(\n",
    "#                     y_trt_subset, y_tva,\n",
    "#     D_trt_subset, true_best, all_policies, profile_map, min_dosage_best_policy, true_best_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dab14f54-6a67-41a4-ba5f-70c2300292fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse_te': 2.65225707739319,\n",
       " 'max_te_est': 3.347887373599511,\n",
       " 'max_te_err': 3.652112626400489,\n",
       " 'iou': 0.42857142857142855,\n",
       " 'conf_matrix': array([[ 2,  0,  8],\n",
       "        [ 0,  0,  2],\n",
       "        [ 0,  0, 36]])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trt_lasso = lasso.predict(D_matrix_trt)\n",
    "y_ctl_lasso = lasso.predict(D_matrix_ctl)\n",
    "\n",
    "te_lasso = y_trt_lasso - y_ctl_lasso\n",
    "\n",
    "tva_results = metrics.compute_te_het_metrics(\n",
    "    te_true, te_lasso,\n",
    "    max_te, max_te_policies,\n",
    "    D_trt, policies_ids_profiles[trt_profile_idx]\n",
    ")\n",
    "\n",
    "tva_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9e57f-40ec-4356-898d-9ec83b2ad097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8214421-9a79-4d6b-9ebe-d1f0e18ef751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sqrd_err': 0.23522551170666117,\n",
       " 'iou': 0.16666666666666666,\n",
       " 'best_prof': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " 'min_dos_inc': False,\n",
       " 'best_pol_diff': -0.03413597934468626}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tva_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e5103-9a0a-4648-a884-96bb1cfd2834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a02e7-f62c-4826-a86c-546b4e9e2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79170d-1b71-4c4d-9913-8a7d692e4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mat_unique = np.unique(D_matrix_trt_subset, axis=0)\n",
    "\n",
    "y_est = np.matmul(D_mat_unique, alpha_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090db9b9-174a-437a-aa08-ade6fe7414d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44d051-3460-4ff2-ad4e-af83fd6ad359",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(D_trt_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23753296-6662-486d-a83d-44f0ed817f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
